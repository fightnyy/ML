{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:54:48.508891Z",
     "start_time": "2020-06-07T06:54:48.247497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moon Jeong-Hyeon \n",
      "last updated: 2020-06-21 \n",
      "\n",
      "numpy 1.18.3\n",
      "pandas 1.0.3\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Moon Jeong-Hyeon' -u -d -p numpy,pandas,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** 코딩해야할 부분을 제외하고는 수정하지 마세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.109724Z",
     "start_time": "2020-06-07T06:54:49.615474Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_sci = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.494027Z",
     "start_time": "2020-06-07T06:55:03.117550Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_, y_test_ = train_test_split(mnist_sci.data, mnist_sci.target, \n",
    "                                                    test_size = 0.1,\n",
    "                                                   shuffle = True)\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "x_train = x_train.reshape(-1,1,28,28)\n",
    "x_test = x_test.reshape(-1,1,28,28)\n",
    "\n",
    "def one_hoy_label(X):\n",
    "    T = np.zeros((X.size, 10))    \n",
    "    for idx, row in enumerate(T):\n",
    "        row[int(X[idx])] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "y_train = one_hoy_label(y_train_)\n",
    "y_test = one_hoy_label(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CE:\n",
    "    \"\"\"\n",
    "    편의를 위해서 softmax와 crossenropy를 결합한 것입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = CE_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1 에서 구현한 것을 바탕으로 CNN도 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask=(x<=0)\n",
    "        out=x.copy()\n",
    "        out[self.mask]=0\n",
    "        return out\n",
    "\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask]=0\n",
    "        dx=dout\n",
    "\n",
    "        return dx\n",
    "\n",
    "class FClayer:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0) \n",
    "        dx = dx.reshape(*self.original_x_shape)  \n",
    "        return dx\n",
    "\n",
    "    \n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "    x = x - np.max(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "    \n",
    "def CE_loss(y, t):\n",
    "    if y.ndim==1:\n",
    "        t=t.reshape(1,t.size)\n",
    "        y=y.reshape(1,y.size)\n",
    "        \n",
    "        batch_size=y.shape[0]\n",
    "    \n",
    "        return -np.sum(t*np.log(y+1e-7))/batch_size\n",
    "     \n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None   \n",
    "        \n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "       \n",
    "        self.x = x[:]  \n",
    "        \n",
    "        FN, C_, FH, FW = self.W.shape# 가중치 즉 필터의 형태\n",
    "        N, C, H, W = x.shape# 인풋의 형태\n",
    "        \n",
    "        \n",
    "        self.out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        self.out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w   \n",
    "        \n",
    "        # padding #그냥 단지 써준 것 형식채우기 pad 값이 0이니까\n",
    "        pad_x = np.pad(x,((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \"constant\", constant_values=0)\n",
    "        \n",
    "\n",
    "        out = np.zeros((N, FN, out_h, out_w))\n",
    "         ######################################################################\n",
    "          # 문제 2-1-1 forward를 구현 하세요                                   #\n",
    "         ######################################################################\n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        out[n, f, j, i] = np.sum(\n",
    "                        pad_x[n, :, j*self.stride:j*self.stride+FH, i*self.stride:i*self.stride+FW]\\\n",
    "                            *self.W[f]) + self.b[f]\n",
    "          ######################################################################\n",
    "          #                          END OF YOUR CODE                          #\n",
    "         ######################################################################              \n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = self.x.shape\n",
    "        \n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w\n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            self.x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \"constant\", constant_values=0)\n",
    "        dx = np.zeros(pad_x.shape)\n",
    "        dw = np.zeros(self.W.shape)\n",
    "        db = np.zeros(self.b.shape)\n",
    "        \n",
    "    \n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-2 backward 구현 하세요                                   #\n",
    "                        ###################################################################### \n",
    "                        dw[f] += pad_x[n, :, j*self.stride:j*self.stride+FH, i*self.stride:i*self.stride+FW] * dout[n, f, j, i]\n",
    "                        dx[n, :, j*self.stride:j*self.stride+FH, i*self.stride:i*self.stride+FW] += self.W[f] * dout[n, f, j, i]\n",
    "                db[f] += np.sum(dout[n, f])\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "                        \n",
    "        # remove padding\n",
    "        dx = dx[:, :, self.pad:dx.shape[2]-self.pad, self.pad:dx.shape[3]-self.pad]\n",
    "        self.db = db\n",
    "        self.dW = dw        \n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad  \n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x[:]\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        \n",
    "        out = np.zeros((N, C, out_h, out_w))\n",
    "        for i in range(out_w):\n",
    "            for j in range(out_h):    \n",
    "                ######################################################################\n",
    "                # 문제 2-2-1 forward를 구현 하세요                                   #\n",
    "                ######################################################################\n",
    "                 out[:, :, j, i] = np.max(x[:, :, j*self.stride:j*self.stride+self.pool_h,\\\n",
    "                 i*self.stride:i*self.stride+self.pool_w], axis=(-1, -2)) \n",
    "                ######################################################################\n",
    "                #                          END OF YOUR CODE                          #\n",
    "                ######################################################################\n",
    "        return out\n",
    "    \n",
    "              \n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, C, H, W = self.x.shape\n",
    "        out_h = (H-self.pool_h) // self.stride + 1\n",
    "        out_w = (W-self.pool_w) // self.stride + 1\n",
    "\n",
    "        dx=np.zeros(self.x.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for i in range(out_w):\n",
    "                    for j in range(out_h):\n",
    "                        ######################################################################\n",
    "                        # Q. 2-2-2 backward를 구현하세요                                         #\n",
    "                        ######################################################################\n",
    "                        backpooling = self.x[n,c,j*self.stride:j*self.stride+self.pool_h,i*self.stride:i*self.stride+self.pool_w]\n",
    "                        dpooling = np.zeros(self.pool_h * self.pool_w)\n",
    "                        dpooling[np.argmax(backpooling)] = 1\n",
    "                        dpooling = dpooling.reshape((self.pool_h, self.pool_w))\n",
    "                        dx[n,c,j*self.stride:j*self.stride+self.pool_h,i*self.stride:i*self.stride+self.pool_w] += dpooling * dout[n, c, j, i]\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################        \n",
    "        return dx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:19.163192Z",
     "start_time": "2020-06-07T06:55:19.146865Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        weight_init_std = 0.01\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        \n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        \n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Conv(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = MaxPooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['FClayer1'] = FClayer(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['FClayer2'] = FClayer(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = Softmax_CE()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        ######################################################################\n",
    "        #  2-3 해당 주어진 gradient 함수에 주석을 다세요                     #\n",
    "        ######################################################################\n",
    "        \n",
    "        # 매개변수의 기울기는 오차역전파법으로 구함. 이과정은 순전파와 역전파를 반복\n",
    "        \n",
    "        #순전파 과정\n",
    "        # forward\n",
    "        # 손실함수의 값을 구한다. 인수 x는 이미지 데이터 ,t는 정답레이블에 해당한다.\n",
    "        self.loss(x, t)\n",
    "        #역전파 과정\n",
    "        # backward 1로 시작한다\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)#신경망에 마지막층 이경우엔 Softmax_CE()에 해당한다.\n",
    "    \n",
    "        layers = list(self.layers.values())#각층의 값들을 layers에 저장한다.\n",
    "        #reverse를 한 이유는 backwards 맨 뒤에서부터 시작해야하기 때문이다.\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # grads라는 딕셔너리 변수에 각 가중치 매개변수의 기울기를 저장. \n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['FClayer1'].dW, self.layers['FClayer1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['FClayer2'].dW, self.layers['FClayer2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:20.334140Z",
     "start_time": "2020-06-07T06:55:20.301677Z"
    }
   },
   "outputs": [],
   "source": [
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 3, 'filter_size': 3, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=16, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습이 되기전 conv layer 의 파라미터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACTElEQVR4nO3cvYricBSG8aOslR+FiYgg7m0I3oOXEFAvxCbgLQjCNN6CYGEp1raWWqk41oKC/202i8XsDnLcr5fnVw3oOUngIVgkkwshGPC/y//tEwBegZAhgZAhgZAhgZAhgZAh4cszXy6XyyGKItcBd7udaz5TqVRc85fLxa7Xa87MrFqthmaz6dq33W5d85lSqeTesd/v30MItTiOQ6vVcu3K519zrzufz+4d2+32PYRQ++izp0KOosiGw6HrZPr9vms+0+l0XPOr1erH381m02azmWvfYDBwzWfa7bZ7R5qmOzOzVqtly+XStatYLLrPx8xsOp26dyRJ8tO7ID8tIIGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIeGpxzjjOLZer+c6YKFQcM1n3t7eXPOP/wbhcDjYaDRy7VssFq75zGazce9I09TMzNbrtfv55vv97j4fs9c8nvor3JEhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAhgZAh4ak3RG63mx2PR9cBu92uaz4zmUxc849viJxOJxuPx659jUbDNZ/xXtejer1uSZK4dszn85eci/cNnM9wR4YEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoaE3OMD5p9+OZc7mdnu953OH/U1hFAzk7sus+/XpnpdH33wVMjAv4qfFpBAyJBAyJBAyJBAyJBAyJBAyJBAyJBAyJDwDUWOeeUYfo21AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test acc | 0.11071428571428571\n",
      " test acc | 0.8934285714285715\n",
      " test acc | 0.9245714285714286\n"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "test_acc_list = []\n",
    "epochs = 3\n",
    "step = int(train_size / batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range(step):\n",
    "        x_batch = x_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        y_batch = y_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        grad = network.gradient(x_batch, y_batch)\n",
    "\n",
    "\n",
    "        # 매개변수 갱신\n",
    "        for key in network.params.keys():\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "            \n",
    "\n",
    "        # 학습 경과 기록\n",
    "        loss = network.loss(x_batch, y_batch)\n",
    "\n",
    "    test_acc = network.accuracy(x_test, y_test)\n",
    "    print(\" test acc | \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 후 파라미터 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACVklEQVR4nO3csYriUBSH8ZNlHARRUQgKCttpYa9gZeebOKXoQwh2loIP4CsI8wy+gSBBux1EhWls7ha7mWqEzR5hdv98vypg7skNfIQUahRCMOB/9+2rNwA8AiFDAiFDAiFDAiFDAiFDwlOWk8vlcqjX664Lnk4n1/pUPp937+P9/T0yMysUCqFarbrmHY9H1/rU8/Oze8btdnsLIcTFYjHEceya9fSUKZG7SqWSe8Z2u30LIXx6Q5l2Wa/XbblcujazXq9d61Ptdtu1frFYfBxXq1WbTqeued71qUaj4Z6x3+8TM7M4jm02m7lmVSoV937MzIbDoXtGFEXJvc94tYAEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoaETF/jvFwuttlsXBdcrVau9anBYOBafz6fP45rtZpNJhPXvF6v51qf6na77hm5XM7MzJIksZeXF9es6/Xq3o+Z2Wg0esice3giQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQ0KmX4g0m02bz+euC/b7fdf6VPoriL81Ho8/jq/Xq72+vrrmJcnd/6DOpNPpPGSO2a9/9W+1Wq4Zu93uIXs5HA4PmXMPT2RIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIIGRIiEIIf35yFP0ws8d8g/zrfQ8hxGZy92X2+95U7+uzDzKFDPyreLWABEKGBEKGBEKGBEKGBEKGBEKGBEKGBEKGhJ+XUW00iXJg0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "#  2-4 학습된 필터를 캡처하여 제출하세요                                      #\n",
    "######################################################################\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
